// This file is AUTO-GENERATED by build.rs from models.json
// DO NOT EDIT MANUALLY - changes will be overwritten
// To modify models, edit models.json and rebuild

/// Embedding dimension specification supporting fixed and Matryoshka dimensions.
#[derive(Debug, Clone, PartialEq)]
pub enum EmbeddingDimension {
    /// Fixed dimension size
    Fixed(usize),
    /// Matryoshka representation with variable dimensions
    Matryoshka {
        /// Default/recommended dimension
        default: usize,
        /// Minimum supported dimension
        min: usize,
        /// Maximum supported dimension
        max: usize,
        /// Explicitly supported dimension values
        supported: &'static [usize],
        /// Truncation strategy (when to apply Matryoshka truncation)
        strategy: Option<&'static str>,
    },
}

impl EmbeddingDimension {
    /// Get the default dimension size
    pub fn default_dim(&self) -> usize {
        match self {
            EmbeddingDimension::Fixed(d) => *d,
            EmbeddingDimension::Matryoshka { default, .. } => *default,
        }
    }

    /// Check if a specific dimension is supported
    pub fn supports_dimension(&self, dim: usize) -> bool {
        match self {
            EmbeddingDimension::Fixed(d) => *d == dim,
            EmbeddingDimension::Matryoshka { supported, .. } => {
                supported.contains(&dim)
            }
        }
    }

    /// Get all supported dimensions
    pub fn supported_dimensions(&self) -> Vec<usize> {
        match self {
            EmbeddingDimension::Fixed(d) => vec![*d],
            EmbeddingDimension::Matryoshka { supported, .. } => {
                supported.to_vec()
            }
        }
    }

    /// Get the Matryoshka truncation strategy, if applicable
    pub fn matryoshka_strategy(&self) -> Option<&'static str> {
        match self {
            EmbeddingDimension::Fixed(_) => None,
            EmbeddingDimension::Matryoshka { strategy, .. } => *strategy,
        }
    }
}

impl std::fmt::Display for EmbeddingDimension {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            EmbeddingDimension::Fixed(d) => write!(f, "{}", d),
            EmbeddingDimension::Matryoshka { default, min, max, strategy, .. } => {
                let strategy_str = strategy.map(|s| format!(" [{}]", s)).unwrap_or_default();
                write!(f, "{} (Matryoshka: {}-{}{})", default, min, max, strategy_str)
            }
        }
    }
}

/// Pooling strategy for dense encodings.
///
/// Determines how token-level embeddings are aggregated into a single vector.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PoolingStrategy {
    /// Use the `[CLS]` token embedding (first token).
    ///
    /// Common in BERT-style models where `[CLS]` is trained to represent
    /// the entire sequence.
    Cls,

    /// Average all token embeddings (weighted by attention mask).
    ///
    /// Produces a centroid representation of all tokens, ignoring padding.
    /// Most common strategy in sentence transformers.
    Mean,

    /// Element-wise maximum across all token embeddings.
    ///
    /// Captures the most salient features from any token position.
    Max,
}

/// Pooling configuration for dense embedding models.
///
/// Specifies how token-level embeddings should be pooled into a single
/// vector representation, and whether the result should be normalized.
#[derive(Debug, Clone, Copy)]
pub struct PoolingConfig {
    /// The pooling strategy to use
    pub strategy: PoolingStrategy,
    /// Whether to L2-normalize the pooled embedding
    pub normalize: bool,
}

/// Type of embedding model.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum ModelType {
    /// Colbert model
    Colbert,
    /// Dense model
    Dense,
    /// Sparse model
    Sparse,
    /// Timeseries model
    Timeseries,
    /// Unified model
    Unified,
    /// VisionLanguage model
    VisionLanguage,
}


/// Comprehensive metadata for a model from the registry.
#[derive(Debug, Clone)]
pub struct ModelInfo {
    /// Unique identifier (kebab-case)
    pub id: &'static str,
    /// Model category
    pub model_type: ModelType,
    /// Display name
    pub name: &'static str,
    /// HuggingFace Hub repository ID
    pub huggingface_id: &'static str,
    /// Organization that released the model
    pub organization: &'static str,
    /// Release year or date
    pub release_date: &'static str,
    /// Architecture type (bert, distilbert, jina-bert, etc.)
    pub architecture_type: &'static str,
    /// Architecture variant
    pub architecture_variant: &'static str,
    /// Whether model has a projection layer
    pub has_projection: bool,
    /// Projection output dimensions (if applicable)
    pub projection_dims: Option<usize>,
    /// Pooling configuration (for dense models)
    pub pooling: Option<PoolingConfig>,
    /// Number of parameters (as string, e.g., "110M")
    pub parameters: &'static str,
    /// Embedding dimension specification (fixed or Matryoshka)
    pub embedding_dim: EmbeddingDimension,
    /// Hidden layer dimensions
    pub hidden_dim: usize,
    /// Maximum sequence length
    pub context_length: usize,
    /// Maximum position embeddings
    pub max_position_embeddings: usize,
    /// Vocabulary size
    pub vocab_size: usize,
    /// Supported languages
    pub languages: &'static [&'static str],
    /// Supported modalities
    pub modalities: &'static [&'static str],
    /// Whether model supports multi-vector embeddings
    pub multi_vector: bool,
    /// Available quantization methods
    pub quantization: &'static [&'static str],
    /// BEIR average score (if available)
    pub beir_avg: f64,
    /// MS MARCO MRR@10 score (if available)
    pub ms_marco_mrr10: f64,
    /// License
    pub license: &'static str,
    /// Description
    pub description: &'static str,
}

/// SPLADE v3
///
/// Sparse lexical retrieval using learned term expansion. Vocabulary-sized vectors with 99.82% sparsity for efficient inverted index storage.
///
/// - Organization: Naver Labs
/// - Release: 2023
/// - Parameters: 66M
/// - Embedding dim: 30522
/// - Context length: 512
/// - Languages: 1
pub const SPLADE_V3: ModelInfo = ModelInfo {
    id: "splade-v3",
    model_type: ModelType::Sparse,
    name: "SPLADE v3",
    huggingface_id: "naver/splade-v3",
    organization: "Naver Labs",
    release_date: "2023",
    architecture_type: "bert",
    architecture_variant: "distilbert-base",
    has_projection: false,
    projection_dims: None,
    pooling: None,
    parameters: "66M",
    embedding_dim: EmbeddingDimension::Fixed(30522),
    hidden_dim: 768,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 30522,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16"],
    beir_avg: 0.49,
    ms_marco_mrr10: 0.38,
    license: "CC-BY-NC-SA-4.0",
    description: "Sparse lexical retrieval using learned term expansion. Vocabulary-sized vectors with 99.82% sparsity for efficient inverted index storage.",
};

/// miniCOIL v1
///
/// Compact sparse retrieval model with 4-dimensional term vectors. Highly efficient for inverted index storage with competitive performance.
///
/// - Organization: Qdrant
/// - Release: 2024
/// - Parameters: 66M
/// - Embedding dim: 4
/// - Context length: 512
/// - Languages: 1
pub const MINICOIL_V1: ModelInfo = ModelInfo {
    id: "minicoil-v1",
    model_type: ModelType::Sparse,
    name: "miniCOIL v1",
    huggingface_id: "Qdrant/minicoil-v1",
    organization: "Qdrant",
    release_date: "2024",
    architecture_type: "bert",
    architecture_variant: "distilbert-base",
    has_projection: true,
    projection_dims: Some(4),
    pooling: None,
    parameters: "66M",
    embedding_dim: EmbeddingDimension::Fixed(4),
    hidden_dim: 768,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 30522,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.46,
    ms_marco_mrr10: 0.35,
    license: "Apache-2.0",
    description: "Compact sparse retrieval model with 4-dimensional term vectors. Highly efficient for inverted index storage with competitive performance.",
};

/// SPLADE++ EN v1
///
/// SPLADE++ efficient sparse embedding model with automatic token expansion for retrieval tasks. Uses BERT-base with MLM head and restrictive FLOPS schedule (doc:128, query:24 tokens).
///
/// - Organization: prithivida
/// - Release: 2024
/// - Parameters: 109M
/// - Embedding dim: 30522
/// - Context length: 512
/// - Languages: 1
pub const SPLADE_PP_EN_V1: ModelInfo = ModelInfo {
    id: "splade-pp-en-v1",
    model_type: ModelType::Sparse,
    name: "SPLADE++ EN v1",
    huggingface_id: "prithivida/Splade_PP_en_v1",
    organization: "prithivida",
    release_date: "2024",
    architecture_type: "bert",
    architecture_variant: "bert-base-uncased",
    has_projection: false,
    projection_dims: None,
    pooling: None,
    parameters: "109M",
    embedding_dim: EmbeddingDimension::Fixed(30522),
    hidden_dim: 768,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 30522,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &[],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.3722,
    license: "apache-2.0",
    description: "SPLADE++ efficient sparse embedding model with automatic token expansion for retrieval tasks. Uses BERT-base with MLM head and restrictive FLOPS schedule (doc:128, query:24 tokens).",
};

/// SPLADE++ EN v2
///
/// Improved SPLADE++ v2 with middle-trained BERT-base (MLM loss) for better corpus awareness. Achieves 37.8 MRR@10 with efficient token budget and 48.81ms retrieval latency.
///
/// - Organization: prithivida
/// - Release: 2024
/// - Parameters: 109M
/// - Embedding dim: 30522
/// - Context length: 512
/// - Languages: 1
pub const SPLADE_PP_EN_V2: ModelInfo = ModelInfo {
    id: "splade-pp-en-v2",
    model_type: ModelType::Sparse,
    name: "SPLADE++ EN v2",
    huggingface_id: "prithivida/Splade_PP_en_v2",
    organization: "prithivida",
    release_date: "2024",
    architecture_type: "bert",
    architecture_variant: "bert-base-uncased",
    has_projection: false,
    projection_dims: None,
    pooling: None,
    parameters: "109M",
    embedding_dim: EmbeddingDimension::Fixed(30522),
    hidden_dim: 768,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 30522,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &[],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.378,
    license: "apache-2.0",
    description: "Improved SPLADE++ v2 with middle-trained BERT-base (MLM loss) for better corpus awareness. Achieves 37.8 MRR@10 with efficient token budget and 48.81ms retrieval latency.",
};

/// TimesFM 1.0 200M
///
/// Pre-trained time series foundation model using decoder-only transformer. Supports context of 512 time points with strong zero-shot forecasting.
///
/// - Organization: Google Research
/// - Release: 2024
/// - Parameters: 200M
/// - Embedding dim: 1280
/// - Context length: 512
/// - Languages: 0
pub const TIMESFM_1_0_200M: ModelInfo = ModelInfo {
    id: "timesfm-1.0-200m",
    model_type: ModelType::Timeseries,
    name: "TimesFM 1.0 200M",
    huggingface_id: "google/timesfm-1.0-200m",
    organization: "Google Research",
    release_date: "2024",
    architecture_type: "decoder-transformer",
    architecture_variant: "patched-decoder",
    has_projection: false,
    projection_dims: None,
    pooling: None,
    parameters: "200M",
    embedding_dim: EmbeddingDimension::Fixed(1280),
    hidden_dim: 1280,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 0,
    languages: &[],
    modalities: &["timeseries"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.0,
    license: "Apache-2.0",
    description: "Pre-trained time series foundation model using decoder-only transformer. Supports context of 512 time points with strong zero-shot forecasting.",
};

/// Chronos Bolt Small
///
/// Efficient T5 encoder-decoder model for probabilistic time series forecasting. Uses continuous patch-based encoding (NOT discrete tokenization like original Chronos). Predicts 9 quantiles for uncertainty quantification. 250x faster than original Chronos. Trained on 100B observations with direct multi-step forecasting.
///
/// - Organization: Amazon
/// - Release: 2024
/// - Parameters: 48M
/// - Embedding dim: 512
/// - Context length: 2048
/// - Languages: 0
pub const CHRONOS_BOLT_SMALL: ModelInfo = ModelInfo {
    id: "chronos-bolt-small",
    model_type: ModelType::Timeseries,
    name: "Chronos Bolt Small",
    huggingface_id: "amazon/chronos-bolt-small",
    organization: "Amazon",
    release_date: "2024",
    architecture_type: "t5",
    architecture_variant: "t5-encoder-decoder",
    has_projection: true,
    projection_dims: Some(512),
    pooling: None,
    parameters: "48M",
    embedding_dim: EmbeddingDimension::Fixed(512),
    hidden_dim: 2048,
    context_length: 2048,
    max_position_embeddings: 2048,
    vocab_size: 2,
    languages: &[],
    modalities: &["timeseries"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.0,
    license: "Apache-2.0",
    description: "Efficient T5 encoder-decoder model for probabilistic time series forecasting. Uses continuous patch-based encoding (NOT discrete tokenization like original Chronos). Predicts 9 quantiles for uncertainty quantification. 250x faster than original Chronos. Trained on 100B observations with direct multi-step forecasting.",
};

/// ColBERT v2
///
/// Original ColBERT v2 from Stanford, baseline for late interaction retrieval. Uses BERT-base with projection layer to 128 dimensions.
///
/// - Organization: Stanford NLP
/// - Release: 2022
/// - Parameters: 110M
/// - Embedding dim: 128
/// - Context length: 512
/// - Languages: 1
pub const COLBERT_V2: ModelInfo = ModelInfo {
    id: "colbert-v2",
    model_type: ModelType::Colbert,
    name: "ColBERT v2",
    huggingface_id: "colbert-ir/colbertv2.0",
    organization: "Stanford NLP",
    release_date: "2022",
    architecture_type: "bert",
    architecture_variant: "bert-base",
    has_projection: true,
    projection_dims: Some(128),
    pooling: None,
    parameters: "110M",
    embedding_dim: EmbeddingDimension::Fixed(128),
    hidden_dim: 768,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 30522,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: true,
    quantization: &["fp32", "fp16", "int8", "binary"],
    beir_avg: 0.52,
    ms_marco_mrr10: 0.39,
    license: "MIT",
    description: "Original ColBERT v2 from Stanford, baseline for late interaction retrieval. Uses BERT-base with projection layer to 128 dimensions.",
};

/// ColBERT Small
///
/// Compact ColBERT variant based on DistilBERT. Recommended for development and testing due to smaller size and faster inference.
///
/// - Organization: Answer.AI
/// - Release: 2024
/// - Parameters: 33M
/// - Embedding dim: 96
/// - Context length: 512
/// - Languages: 1
pub const COLBERT_SMALL: ModelInfo = ModelInfo {
    id: "colbert-small",
    model_type: ModelType::Colbert,
    name: "ColBERT Small",
    huggingface_id: "answerdotai/answerai-colbert-small-v1",
    organization: "Answer.AI",
    release_date: "2024",
    architecture_type: "distilbert",
    architecture_variant: "distilbert-base",
    has_projection: true,
    projection_dims: Some(96),
    pooling: None,
    parameters: "33M",
    embedding_dim: EmbeddingDimension::Fixed(96),
    hidden_dim: 384,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 30522,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: true,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.45,
    ms_marco_mrr10: 0.32,
    license: "Apache-2.0",
    description: "Compact ColBERT variant based on DistilBERT. Recommended for development and testing due to smaller size and faster inference.",
};

/// Jina ColBERT v2
///
/// Multilingual ColBERT supporting 89 languages with extended 8K context length. Supports Matryoshka representations from 64 to 768 dimensions.
///
/// - Organization: Jina AI
/// - Release: 2024
/// - Parameters: 560M
/// - Embedding dim: 768 (Matryoshka: 64-768 [\truncate_output\])
/// - Context length: 8192
/// - Languages: 88
pub const JINA_COLBERT_V2: ModelInfo = ModelInfo {
    id: "jina-colbert-v2",
    model_type: ModelType::Colbert,
    name: "Jina ColBERT v2",
    huggingface_id: "jinaai/jina-colbert-v2",
    organization: "Jina AI",
    release_date: "2024",
    architecture_type: "jina-bert",
    architecture_variant: "jina-bert-v2-base-en",
    has_projection: false,
    projection_dims: None,
    pooling: None,
    parameters: "560M",
    embedding_dim: EmbeddingDimension::Matryoshka { default: 768, min: 64, max: 768, supported: &[64, 96, 128, 256, 384, 512, 768], strategy: Some("truncate_output") },
    hidden_dim: 768,
    context_length: 8192,
    max_position_embeddings: 8192,
    vocab_size: 30528,
    languages: &["en", "de", "fr", "es", "it", "pt", "nl", "pl", "ru", "zh", "ja", "ko", "ar", "hi", "th", "tr", "vi", "id", "ms", "fa", "uk", "ro", "cs", "sv", "da", "no", "fi", "el", "he", "bg", "hr", "sk", "sl", "et", "lv", "lt", "hu", "ca", "eu", "gl", "cy", "sq", "mk", "sr", "bs", "mt", "is", "ga", "af", "sw", "zu", "xh", "st", "tn", "ny", "sn", "yo", "ig", "ha", "am", "ti", "om", "so", "mg", "mi", "sm", "to", "fj", "haw", "ht", "qu", "gn", "ay", "tt", "ug", "kk", "ky", "tg", "uz", "tk", "mn", "bo", "dz", "ne", "si", "my", "km", "lo"],
    modalities: &["text"],
    multi_vector: true,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.54,
    ms_marco_mrr10: 0.42,
    license: "Apache-2.0",
    description: "Multilingual ColBERT supporting 89 languages with extended 8K context length. Supports Matryoshka representations from 64 to 768 dimensions.",
};

/// Jina ColBERT v2 (96-dim)
///
/// Jina ColBERT v2 at 96 dimensions for compact storage with minimal quality loss.
///
/// - Organization: Jina AI
/// - Release: 2024
/// - Parameters: 560M
/// - Embedding dim: 96
/// - Context length: 8192
/// - Languages: 88
pub const JINA_COLBERT_V2_96: ModelInfo = ModelInfo {
    id: "jina-colbert-v2-96",
    model_type: ModelType::Colbert,
    name: "Jina ColBERT v2 (96-dim)",
    huggingface_id: "jinaai/jina-colbert-v2",
    organization: "Jina AI",
    release_date: "2024",
    architecture_type: "jina-bert",
    architecture_variant: "jina-bert-v2-base-en",
    has_projection: false,
    projection_dims: None,
    pooling: None,
    parameters: "560M",
    embedding_dim: EmbeddingDimension::Fixed(96),
    hidden_dim: 768,
    context_length: 8192,
    max_position_embeddings: 8192,
    vocab_size: 30528,
    languages: &["en", "de", "fr", "es", "it", "pt", "nl", "pl", "ru", "zh", "ja", "ko", "ar", "hi", "th", "tr", "vi", "id", "ms", "fa", "uk", "ro", "cs", "sv", "da", "no", "fi", "el", "he", "bg", "hr", "sk", "sl", "et", "lv", "lt", "hu", "ca", "eu", "gl", "cy", "sq", "mk", "sr", "bs", "mt", "is", "ga", "af", "sw", "zu", "xh", "st", "tn", "ny", "sn", "yo", "ig", "ha", "am", "ti", "om", "so", "mg", "mi", "sm", "to", "fj", "haw", "ht", "qu", "gn", "ay", "tt", "ug", "kk", "ky", "tg", "uz", "tk", "mn", "bo", "dz", "ne", "si", "my", "km", "lo"],
    modalities: &["text"],
    multi_vector: true,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.53,
    ms_marco_mrr10: 0.41,
    license: "Apache-2.0",
    description: "Jina ColBERT v2 at 96 dimensions for compact storage with minimal quality loss.",
};

/// Jina ColBERT v2 (64-dim)
///
/// Jina ColBERT v2 at 64 dimensions for maximum compactness.
///
/// - Organization: Jina AI
/// - Release: 2024
/// - Parameters: 560M
/// - Embedding dim: 64
/// - Context length: 8192
/// - Languages: 88
pub const JINA_COLBERT_V2_64: ModelInfo = ModelInfo {
    id: "jina-colbert-v2-64",
    model_type: ModelType::Colbert,
    name: "Jina ColBERT v2 (64-dim)",
    huggingface_id: "jinaai/jina-colbert-v2",
    organization: "Jina AI",
    release_date: "2024",
    architecture_type: "jina-bert",
    architecture_variant: "jina-bert-v2-base-en",
    has_projection: false,
    projection_dims: None,
    pooling: None,
    parameters: "560M",
    embedding_dim: EmbeddingDimension::Fixed(64),
    hidden_dim: 768,
    context_length: 8192,
    max_position_embeddings: 8192,
    vocab_size: 30528,
    languages: &["en", "de", "fr", "es", "it", "pt", "nl", "pl", "ru", "zh", "ja", "ko", "ar", "hi", "th", "tr", "vi", "id", "ms", "fa", "uk", "ro", "cs", "sv", "da", "no", "fi", "el", "he", "bg", "hr", "sk", "sl", "et", "lv", "lt", "hu", "ca", "eu", "gl", "cy", "sq", "mk", "sr", "bs", "mt", "is", "ga", "af", "sw", "zu", "xh", "st", "tn", "ny", "sn", "yo", "ig", "ha", "am", "ti", "om", "so", "mg", "mi", "sm", "to", "fj", "haw", "ht", "qu", "gn", "ay", "tt", "ug", "kk", "ky", "tg", "uz", "tk", "mn", "bo", "dz", "ne", "si", "my", "km", "lo"],
    modalities: &["text"],
    multi_vector: true,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.51,
    ms_marco_mrr10: 0.39,
    license: "Apache-2.0",
    description: "Jina ColBERT v2 at 64 dimensions for maximum compactness.",
};

/// ColPali v1.2 Merged
///
/// Vision-language ColBERT model for document retrieval. Encodes page images as multi-vector patch embeddings for OCR-free document search using late interaction. Based on PaliGemma-3B with fixed initialization and right padding.
///
/// - Organization: vidore
/// - Release: 2024
/// - Parameters: 3B
/// - Embedding dim: 128
/// - Context length: 512
/// - Languages: 1
pub const COLPALI_V1_2: ModelInfo = ModelInfo {
    id: "colpali-v1.2",
    model_type: ModelType::VisionLanguage,
    name: "ColPali v1.2 Merged",
    huggingface_id: "vidore/colpali-v1.2-merged",
    organization: "vidore",
    release_date: "2024",
    architecture_type: "paligemma",
    architecture_variant: "paligemma-3b-mix-448",
    has_projection: true,
    projection_dims: Some(128),
    pooling: None,
    parameters: "3B",
    embedding_dim: EmbeddingDimension::Fixed(128),
    hidden_dim: 2048,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 257216,
    languages: &["multilingual"],
    modalities: &["vision", "text"],
    multi_vector: true,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.0,
    license: "gemma",
    description: "Vision-language ColBERT model for document retrieval. Encodes page images as multi-vector patch embeddings for OCR-free document search using late interaction. Based on PaliGemma-3B with fixed initialization and right padding.",
};

/// ColPali v1.3 HF
///
/// Latest ColPali vision-language model for document retrieval. Encodes page images as multi-vector patch embeddings for OCR-free document search using late interaction. Improved performance over v1.2 with average NDCG@5 of 0.546 on ViDoRe benchmark.
///
/// - Organization: vidore
/// - Release: 2024
/// - Parameters: 3B
/// - Embedding dim: 128
/// - Context length: 512
/// - Languages: 1
pub const COLPALI_V1_3_HF: ModelInfo = ModelInfo {
    id: "colpali-v1.3-hf",
    model_type: ModelType::VisionLanguage,
    name: "ColPali v1.3 HF",
    huggingface_id: "vidore/colpali-v1.3-hf",
    organization: "vidore",
    release_date: "2024",
    architecture_type: "paligemma",
    architecture_variant: "paligemma-3b-mix-448",
    has_projection: true,
    projection_dims: Some(128),
    pooling: None,
    parameters: "3B",
    embedding_dim: EmbeddingDimension::Fixed(128),
    hidden_dim: 2048,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 257216,
    languages: &["multilingual"],
    modalities: &["vision", "text"],
    multi_vector: true,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.0,
    license: "gemma",
    description: "Latest ColPali vision-language model for document retrieval. Encodes page images as multi-vector patch embeddings for OCR-free document search using late interaction. Improved performance over v1.2 with average NDCG@5 of 0.546 on ViDoRe benchmark.",
};

/// GTE-ModernColBERT v1
///
/// Modern ColBERT model based on ModernBERT architecture with improved reasoning performance. Uses global-local attention and extended 8K context length.
///
/// - Organization: LightOn AI
/// - Release: 2025
/// - Parameters: 130M
/// - Embedding dim: 768
/// - Context length: 8192
/// - Languages: 1
pub const GTE_MODERN_COLBERT: ModelInfo = ModelInfo {
    id: "gte-modern-colbert",
    model_type: ModelType::Colbert,
    name: "GTE-ModernColBERT v1",
    huggingface_id: "lightonai/GTE-ModernColBERT-v1",
    organization: "LightOn AI",
    release_date: "2025",
    architecture_type: "modernbert",
    architecture_variant: "gte-modernbert-base",
    has_projection: false,
    projection_dims: None,
    pooling: None,
    parameters: "130M",
    embedding_dim: EmbeddingDimension::Fixed(768),
    hidden_dim: 768,
    context_length: 8192,
    max_position_embeddings: 8192,
    vocab_size: 50370,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: true,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.68,
    ms_marco_mrr10: 0.75,
    license: "Apache-2.0",
    description: "Modern ColBERT model based on ModernBERT architecture with improved reasoning performance. Uses global-local attention and extended 8K context length.",
};

/// BGE-M3 (Multi-Vector Mode)
///
/// Unified embedding model supporting dense, sparse, and multi-vector representations. Supports 100+ languages with 8K context. 1024 dimensions per token in multi-vector mode.
///
/// - Organization: BAAI
/// - Release: 2024
/// - Parameters: 568M
/// - Embedding dim: 1024
/// - Context length: 8192
/// - Languages: 88
pub const BGE_M3_MULTI: ModelInfo = ModelInfo {
    id: "bge-m3-multi",
    model_type: ModelType::Unified,
    name: "BGE-M3 (Multi-Vector Mode)",
    huggingface_id: "BAAI/bge-m3",
    organization: "BAAI",
    release_date: "2024",
    architecture_type: "xlm-roberta",
    architecture_variant: "xlm-roberta-large",
    has_projection: false,
    projection_dims: None,
    pooling: None,
    parameters: "568M",
    embedding_dim: EmbeddingDimension::Fixed(1024),
    hidden_dim: 1024,
    context_length: 8192,
    max_position_embeddings: 8192,
    vocab_size: 250002,
    languages: &["en", "zh", "es", "fr", "de", "ar", "hi", "ja", "ko", "ru", "th", "tr", "vi", "id", "ms", "fa", "uk", "ro", "cs", "sv", "da", "no", "fi", "el", "he", "bg", "hr", "sk", "sl", "et", "lv", "lt", "hu", "ca", "eu", "gl", "cy", "sq", "mk", "sr", "bs", "mt", "is", "ga", "af", "sw", "zu", "xh", "st", "tn", "ny", "sn", "yo", "ig", "ha", "am", "ti", "om", "so", "mg", "mi", "sm", "to", "fj", "haw", "ht", "qu", "gn", "ay", "tt", "ug", "kk", "ky", "tg", "uz", "tk", "mn", "bo", "dz", "ne", "si", "my", "km", "lo", "pl", "it", "pt", "nl"],
    modalities: &["text"],
    multi_vector: true,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.55,
    ms_marco_mrr10: 0.44,
    license: "MIT",
    description: "Unified embedding model supporting dense, sparse, and multi-vector representations. Supports 100+ languages with 8K context. 1024 dimensions per token in multi-vector mode.",
};

/// Pooling configuration for GTE-Qwen2-7B.
pub const GTE_QWEN2_7B_POOLING: PoolingConfig = PoolingConfig {
    strategy: PoolingStrategy::Mean,
    normalize: true,
};

/// GTE-Qwen2-7B
///
/// State-of-the-art dense retrieval model based on Qwen2-7B decoder with bidirectional attention. Supports Matryoshka dimensions from 512 to 3584.
///
/// - Organization: Alibaba
/// - Release: 2024
/// - Parameters: 7B
/// - Embedding dim: 3584 (Matryoshka: 512-3584 [\truncate_pooled\])
/// - Context length: 32768
/// - Languages: 3
pub const GTE_QWEN2_7B: ModelInfo = ModelInfo {
    id: "gte-qwen2-7b",
    model_type: ModelType::Dense,
    name: "GTE-Qwen2-7B",
    huggingface_id: "Alibaba-NLP/gte-Qwen2-7B-instruct",
    organization: "Alibaba",
    release_date: "2024",
    architecture_type: "qwen2",
    architecture_variant: "qwen2-7b-decoder",
    has_projection: false,
    projection_dims: None,
    pooling: Some(GTE_QWEN2_7B_POOLING),
    parameters: "7B",
    embedding_dim: EmbeddingDimension::Matryoshka { default: 3584, min: 512, max: 3584, supported: &[512, 1024, 2048, 3584], strategy: Some("truncate_pooled") },
    hidden_dim: 3584,
    context_length: 32768,
    max_position_embeddings: 32768,
    vocab_size: 151936,
    languages: &["en", "zh", "multilingual"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8", "int4"],
    beir_avg: 0.62,
    ms_marco_mrr10: 0.51,
    license: "Apache-2.0",
    description: "State-of-the-art dense retrieval model based on Qwen2-7B decoder with bidirectional attention. Supports Matryoshka dimensions from 512 to 3584.",
};

/// Pooling configuration for Nomic Embed v1.5.
pub const NOMIC_EMBED_V1_5_POOLING: PoolingConfig = PoolingConfig {
    strategy: PoolingStrategy::Mean,
    normalize: true,
};

/// Nomic Embed v1.5
///
/// Efficient embedding model with strong performance and Matryoshka support. Extended context window of 8K tokens.
///
/// - Organization: Nomic AI
/// - Release: 2024
/// - Parameters: 137M
/// - Embedding dim: 768 (Matryoshka: 64-768 [\truncate_pooled\])
/// - Context length: 8192
/// - Languages: 1
pub const NOMIC_EMBED_V1_5: ModelInfo = ModelInfo {
    id: "nomic-embed-v1.5",
    model_type: ModelType::Dense,
    name: "Nomic Embed v1.5",
    huggingface_id: "nomic-ai/nomic-embed-text-v1.5",
    organization: "Nomic AI",
    release_date: "2024",
    architecture_type: "bert",
    architecture_variant: "nomic-bert",
    has_projection: false,
    projection_dims: None,
    pooling: Some(NOMIC_EMBED_V1_5_POOLING),
    parameters: "137M",
    embedding_dim: EmbeddingDimension::Matryoshka { default: 768, min: 64, max: 768, supported: &[64, 128, 256, 512, 768], strategy: Some("truncate_pooled") },
    hidden_dim: 768,
    context_length: 8192,
    max_position_embeddings: 8192,
    vocab_size: 30528,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.54,
    ms_marco_mrr10: 0.43,
    license: "Apache-2.0",
    description: "Efficient embedding model with strong performance and Matryoshka support. Extended context window of 8K tokens.",
};

/// Pooling configuration for BGE-Base-EN-v1.5.
pub const BGE_BASE_EN_V1_5_POOLING: PoolingConfig = PoolingConfig {
    strategy: PoolingStrategy::Mean,
    normalize: true,
};

/// BGE-Base-EN-v1.5
///
/// Strong baseline English embedding model from BAAI. Fixed 768-dimensional embeddings with excellent performance.
///
/// - Organization: BAAI
/// - Release: 2023
/// - Parameters: 109M
/// - Embedding dim: 768
/// - Context length: 512
/// - Languages: 1
pub const BGE_BASE_EN_V1_5: ModelInfo = ModelInfo {
    id: "bge-base-en-v1.5",
    model_type: ModelType::Dense,
    name: "BGE-Base-EN-v1.5",
    huggingface_id: "BAAI/bge-base-en-v1.5",
    organization: "BAAI",
    release_date: "2023",
    architecture_type: "bert",
    architecture_variant: "bert-base",
    has_projection: false,
    projection_dims: None,
    pooling: Some(BGE_BASE_EN_V1_5_POOLING),
    parameters: "109M",
    embedding_dim: EmbeddingDimension::Fixed(768),
    hidden_dim: 768,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 30522,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.53,
    ms_marco_mrr10: 0.42,
    license: "MIT",
    description: "Strong baseline English embedding model from BAAI. Fixed 768-dimensional embeddings with excellent performance.",
};

/// Pooling configuration for Snowflake Arctic Embed L.
pub const SNOWFLAKE_ARCTIC_L_POOLING: PoolingConfig = PoolingConfig {
    strategy: PoolingStrategy::Mean,
    normalize: true,
};

/// Snowflake Arctic Embed L
///
/// High-performance large embedding model with Matryoshka support from Snowflake. Strong retrieval performance.
///
/// - Organization: Snowflake
/// - Release: 2024
/// - Parameters: 335M
/// - Embedding dim: 1024 (Matryoshka: 256-1024 [\truncate_pooled\])
/// - Context length: 512
/// - Languages: 1
pub const SNOWFLAKE_ARCTIC_L: ModelInfo = ModelInfo {
    id: "snowflake-arctic-l",
    model_type: ModelType::Dense,
    name: "Snowflake Arctic Embed L",
    huggingface_id: "Snowflake/snowflake-arctic-embed-l-v2.0",
    organization: "Snowflake",
    release_date: "2024",
    architecture_type: "bert",
    architecture_variant: "bert-large",
    has_projection: false,
    projection_dims: None,
    pooling: Some(SNOWFLAKE_ARCTIC_L_POOLING),
    parameters: "335M",
    embedding_dim: EmbeddingDimension::Matryoshka { default: 1024, min: 256, max: 1024, supported: &[256, 512, 768, 1024], strategy: Some("truncate_pooled") },
    hidden_dim: 1024,
    context_length: 512,
    max_position_embeddings: 512,
    vocab_size: 30522,
    languages: &["en"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.56,
    ms_marco_mrr10: 0.45,
    license: "Apache-2.0",
    description: "High-performance large embedding model with Matryoshka support from Snowflake. Strong retrieval performance.",
};

/// Pooling configuration for Qwen3-Embedding-8B.
pub const QWEN3_EMBEDDING_8B_POOLING: PoolingConfig = PoolingConfig {
    strategy: PoolingStrategy::Mean,
    normalize: true,
};

/// Qwen3-Embedding-8B
///
/// State-of-the-art multilingual dense retrieval model based on Qwen3-8B with bidirectional attention. Ranks #1 on MTEB multilingual leaderboard with score of 70.58. Supports Matryoshka dimensions from 32 to 4096 and instruction-aware embeddings across 100+ languages.
///
/// - Organization: Alibaba
/// - Release: 2025
/// - Parameters: 8B
/// - Embedding dim: 4096 (Matryoshka: 32-4096 [\truncate_pooled\])
/// - Context length: 32768
/// - Languages: 3
pub const QWEN3_EMBEDDING_8B: ModelInfo = ModelInfo {
    id: "qwen3-embedding-8b",
    model_type: ModelType::Dense,
    name: "Qwen3-Embedding-8B",
    huggingface_id: "Qwen/Qwen3-Embedding-8B",
    organization: "Alibaba",
    release_date: "2025",
    architecture_type: "qwen3",
    architecture_variant: "qwen3-8b-decoder",
    has_projection: false,
    projection_dims: None,
    pooling: Some(QWEN3_EMBEDDING_8B_POOLING),
    parameters: "8B",
    embedding_dim: EmbeddingDimension::Matryoshka { default: 4096, min: 32, max: 4096, supported: &[32, 64, 128, 256, 512, 1024, 2048, 4096], strategy: Some("truncate_pooled") },
    hidden_dim: 4096,
    context_length: 32768,
    max_position_embeddings: 32768,
    vocab_size: 151936,
    languages: &["en", "zh", "multilingual"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8", "int4"],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.0,
    license: "Apache-2.0",
    description: "State-of-the-art multilingual dense retrieval model based on Qwen3-8B with bidirectional attention. Ranks #1 on MTEB multilingual leaderboard with score of 70.58. Supports Matryoshka dimensions from 32 to 4096 and instruction-aware embeddings across 100+ languages.",
};

/// Pooling configuration for Qwen3-Embedding-4B.
pub const QWEN3_EMBEDDING_4B_POOLING: PoolingConfig = PoolingConfig {
    strategy: PoolingStrategy::Mean,
    normalize: true,
};

/// Qwen3-Embedding-4B
///
/// Efficient multilingual dense retrieval model based on Qwen3-4B. Achieves 69.45 MTEB score with strong retrieval performance. Supports Matryoshka dimensions from 32 to 2560 and instruction-aware embeddings across 100+ languages.
///
/// - Organization: Alibaba
/// - Release: 2025
/// - Parameters: 4B
/// - Embedding dim: 2560 (Matryoshka: 32-2560 [\truncate_pooled\])
/// - Context length: 32768
/// - Languages: 3
pub const QWEN3_EMBEDDING_4B: ModelInfo = ModelInfo {
    id: "qwen3-embedding-4b",
    model_type: ModelType::Dense,
    name: "Qwen3-Embedding-4B",
    huggingface_id: "Qwen/Qwen3-Embedding-4B",
    organization: "Alibaba",
    release_date: "2025",
    architecture_type: "qwen3",
    architecture_variant: "qwen3-4b-decoder",
    has_projection: false,
    projection_dims: None,
    pooling: Some(QWEN3_EMBEDDING_4B_POOLING),
    parameters: "4B",
    embedding_dim: EmbeddingDimension::Matryoshka { default: 2560, min: 32, max: 2560, supported: &[32, 64, 128, 256, 512, 1024, 2048, 2560], strategy: Some("truncate_pooled") },
    hidden_dim: 2560,
    context_length: 32768,
    max_position_embeddings: 32768,
    vocab_size: 151936,
    languages: &["en", "zh", "multilingual"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8", "int4"],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.0,
    license: "Apache-2.0",
    description: "Efficient multilingual dense retrieval model based on Qwen3-4B. Achieves 69.45 MTEB score with strong retrieval performance. Supports Matryoshka dimensions from 32 to 2560 and instruction-aware embeddings across 100+ languages.",
};

/// Pooling configuration for Qwen3-Embedding-0.6B.
pub const QWEN3_EMBEDDING_0_6B_POOLING: PoolingConfig = PoolingConfig {
    strategy: PoolingStrategy::Mean,
    normalize: true,
};

/// Qwen3-Embedding-0.6B
///
/// Compact multilingual dense retrieval model based on Qwen3-0.6B with 28 layers. Achieves 64.33 MTEB score with efficient inference. Supports Matryoshka dimensions from 32 to 1024 and instruction-aware embeddings across 100+ languages.
///
/// - Organization: Alibaba
/// - Release: 2025
/// - Parameters: 0.6B
/// - Embedding dim: 1024 (Matryoshka: 32-1024 [\truncate_pooled\])
/// - Context length: 32768
/// - Languages: 3
pub const QWEN3_EMBEDDING_0_6B: ModelInfo = ModelInfo {
    id: "qwen3-embedding-0.6b",
    model_type: ModelType::Dense,
    name: "Qwen3-Embedding-0.6B",
    huggingface_id: "Qwen/Qwen3-Embedding-0.6B",
    organization: "Alibaba",
    release_date: "2025",
    architecture_type: "qwen3",
    architecture_variant: "qwen3-0.6b-decoder",
    has_projection: false,
    projection_dims: None,
    pooling: Some(QWEN3_EMBEDDING_0_6B_POOLING),
    parameters: "0.6B",
    embedding_dim: EmbeddingDimension::Matryoshka { default: 1024, min: 32, max: 1024, supported: &[32, 64, 128, 256, 512, 1024], strategy: Some("truncate_pooled") },
    hidden_dim: 1024,
    context_length: 32768,
    max_position_embeddings: 32768,
    vocab_size: 151936,
    languages: &["en", "zh", "multilingual"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8", "int4"],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.0,
    license: "Apache-2.0",
    description: "Compact multilingual dense retrieval model based on Qwen3-0.6B with 28 layers. Achieves 64.33 MTEB score with efficient inference. Supports Matryoshka dimensions from 32 to 1024 and instruction-aware embeddings across 100+ languages.",
};

/// Pooling configuration for Jina Embeddings v3.
pub const JINA_EMBEDDINGS_V3_POOLING: PoolingConfig = PoolingConfig {
    strategy: PoolingStrategy::Mean,
    normalize: true,
};

/// Jina Embeddings v3
///
/// Frontier multilingual embedding model with 570M parameters based on XLM-RoBERTa with 24 layers. Features task-specific LoRA adapters for retrieval, classification, and text-matching. Supports 89 languages with extended 8K context using RoPE. Ranks 2nd on MTEB English leaderboard for models under 1B parameters.
///
/// - Organization: Jina AI
/// - Release: 2024
/// - Parameters: 570M
/// - Embedding dim: 1024 (Matryoshka: 32-1024 [\truncate_pooled\])
/// - Context length: 8192
/// - Languages: 12
pub const JINA_EMBEDDINGS_V3: ModelInfo = ModelInfo {
    id: "jina-embeddings-v3",
    model_type: ModelType::Dense,
    name: "Jina Embeddings v3",
    huggingface_id: "jinaai/jina-embeddings-v3",
    organization: "Jina AI",
    release_date: "2024",
    architecture_type: "xlm-roberta",
    architecture_variant: "jina-xlm-roberta",
    has_projection: false,
    projection_dims: None,
    pooling: Some(JINA_EMBEDDINGS_V3_POOLING),
    parameters: "570M",
    embedding_dim: EmbeddingDimension::Matryoshka { default: 1024, min: 32, max: 1024, supported: &[32, 64, 128, 256, 512, 768, 1024], strategy: Some("truncate_pooled") },
    hidden_dim: 1024,
    context_length: 8192,
    max_position_embeddings: 8192,
    vocab_size: 250002,
    languages: &["en", "zh", "de", "fr", "es", "it", "pt", "ja", "ko", "ar", "ru", "multilingual"],
    modalities: &["text"],
    multi_vector: false,
    quantization: &["fp32", "fp16", "int8"],
    beir_avg: 0.0,
    ms_marco_mrr10: 0.0,
    license: "Apache-2.0",
    description: "Frontier multilingual embedding model with 570M parameters based on XLM-RoBERTa with 24 layers. Features task-specific LoRA adapters for retrieval, classification, and text-matching. Supports 89 languages with extended 8K context using RoPE. Ranks 2nd on MTEB English leaderboard for models under 1B parameters.",
};

/// Complete model registry containing all available models.
///
/// This is generated at compile time from models.json.
pub const MODEL_REGISTRY: &[ModelInfo] = &[
    SPLADE_V3,
    MINICOIL_V1,
    SPLADE_PP_EN_V1,
    SPLADE_PP_EN_V2,
    TIMESFM_1_0_200M,
    CHRONOS_BOLT_SMALL,
    COLBERT_V2,
    COLBERT_SMALL,
    JINA_COLBERT_V2,
    JINA_COLBERT_V2_96,
    JINA_COLBERT_V2_64,
    COLPALI_V1_2,
    COLPALI_V1_3_HF,
    GTE_MODERN_COLBERT,
    BGE_M3_MULTI,
    GTE_QWEN2_7B,
    NOMIC_EMBED_V1_5,
    BGE_BASE_EN_V1_5,
    SNOWFLAKE_ARCTIC_L,
    QWEN3_EMBEDDING_8B,
    QWEN3_EMBEDDING_4B,
    QWEN3_EMBEDDING_0_6B,
    JINA_EMBEDDINGS_V3,
];


/// Get a model by its ID.
///
/// # Example
///
/// ```
/// use tessera::model_registry::get_model;
///
/// let model = get_model("colbert-v2").expect("Model not found");
/// assert_eq!(model.embedding_dim.default_dim(), 128);
/// ```
pub fn get_model(id: &str) -> Option<&'static ModelInfo> {
    MODEL_REGISTRY.iter().find(|m| m.id == id)
}

/// Get all models of a specific type.
///
/// # Example
///
/// ```
/// use tessera::model_registry::{models_by_type, ModelType};
///
/// let colbert_models = models_by_type(ModelType::Colbert);
/// for model in colbert_models {
///     println!("{}: {} dims", model.name, model.embedding_dim.default_dim());
/// }
/// ```
pub fn models_by_type(model_type: ModelType) -> Vec<&'static ModelInfo> {
    MODEL_REGISTRY
        .iter()
        .filter(|m| m.model_type == model_type)
        .collect()
}

/// Get all models from a specific organization.
pub fn models_by_organization(organization: &str) -> Vec<&'static ModelInfo> {
    MODEL_REGISTRY
        .iter()
        .filter(|m| m.organization.eq_ignore_ascii_case(organization))
        .collect()
}

/// Get all models supporting a specific language.
pub fn models_by_language(language: &str) -> Vec<&'static ModelInfo> {
    MODEL_REGISTRY
        .iter()
        .filter(|m| m.languages.contains(&language))
        .collect()
}

/// Get all models with default embedding dimension less than or equal to the specified size.
pub fn models_by_max_embedding_dim(max_dim: usize) -> Vec<&'static ModelInfo> {
    MODEL_REGISTRY
        .iter()
        .filter(|m| m.embedding_dim.default_dim() <= max_dim)
        .collect()
}

/// Get all models supporting Matryoshka representation.
pub fn models_with_matryoshka() -> Vec<&'static ModelInfo> {
    MODEL_REGISTRY
        .iter()
        .filter(|m| matches!(m.embedding_dim, EmbeddingDimension::Matryoshka { .. }))
        .collect()
}

/// Get a model by its HuggingFace Hub ID.
///
/// # Example
///
/// ```
/// use tessera::model_registry::get_model_by_hf_id;
///
/// let model = get_model_by_hf_id("jinaai/jina-colbert-v2");
/// assert!(model.is_some());
/// ```
pub fn get_model_by_hf_id(hf_id: &str) -> Option<&'static ModelInfo> {
    MODEL_REGISTRY.iter().find(|m| m.huggingface_id == hf_id)
}